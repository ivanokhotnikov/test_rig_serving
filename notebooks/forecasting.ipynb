{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test rig condition forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pickle import load, dump\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.holtwinters import Holt, ExponentialSmoothing\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('\\\\Users\\\\iokhotnikov\\\\Documents\\\\Python\\\\hhl\\\\test_rig\\\\code')\n",
    "from scripts.utils.readers import DataReader, Preprocessor\n",
    "from scripts.utils.config import FEATURES, FEATURES_NO_TIME, MODELS_PATH, PREDICTIONS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('\\\\Users\\\\iokhotnikov\\\\Documents\\\\Python\\\\hhl\\\\test_rig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(mode='preprocessed'):\n",
    "    if mode == 'raw':\n",
    "        df = DataReader.read_all_raw_data(verbose=True,\n",
    "                                          features_to_read=FEATURES)\n",
    "        df = Preprocessor.remove_step_zero(df, inplace=False)\n",
    "        df.sort_values(by=['DATE', 'TIME'], inplace=True, ignore_index=True)\n",
    "    if mode == 'processed':\n",
    "        df = pd.read_csv(os.path.join('data', 'processed',\n",
    "                                      'combined_timed_data.csv'),\n",
    "                         parse_dates=True,\n",
    "                         infer_datetime_format=True,\n",
    "                         dtype=dict(\n",
    "                             zip(FEATURES_NO_TIME,\n",
    "                                 [np.float32] * len(FEATURES_NO_TIME))))\n",
    "        df[['STEP', 'UNIT', 'TEST',\n",
    "            'ARMANI']] = df[['STEP', 'UNIT', 'TEST',\n",
    "                             'ARMANI']].astype(np.uint8)\n",
    "        df['TIME'] = pd.to_datetime(df['TIME'])\n",
    "        df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df['RUNNING TIME'] = pd.date_range(start=f'{min(df[\"DATE\"])} 00:00:00',\n",
    "                                       periods=len(df),\n",
    "                                       freq='s')\n",
    "    df['RUNNING DURATION'] = pd.to_timedelta(range(len(df)), unit='s')\n",
    "    df['RUNNING HOURS'] = (\n",
    "        pd.to_timedelta(range(len(df)), unit='s').total_seconds() /\n",
    "        3600).astype(np.float32)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(mode='processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect and cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test duration 3649.24 seconds = 60.82 minutes = 1.01 hours\n"
     ]
    }
   ],
   "source": [
    "test_lengths = []\n",
    "for unit in df['UNIT'].unique():\n",
    "    for unit_test in df[df['UNIT'] == unit]['TEST'].unique():\n",
    "        test_lengths.append(\n",
    "            len(df[(df['UNIT'] == unit) & (df['TEST'] == unit_test)]))\n",
    "mean_test_dur_sec = np.mean(test_lengths)\n",
    "print(\n",
    "    f'Mean test duration {mean_test_dur_sec:.2f} seconds = {mean_test_dur_sec/60:.2f} minutes = {mean_test_dur_sec/3600:.2f} hours'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests performed: 58\n"
     ]
    }
   ],
   "source": [
    "print(f'Tests performed: {len(test_lengths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature(df, feature):\n",
    "    plt.figure(figsize=(20, 5), tight_layout=True)\n",
    "    plt.plot(df['RUNNING HOURS'], df[feature])\n",
    "    plt.ylabel(feature)\n",
    "    plt.xlabel('TIME, HOURS')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_data(df):\n",
    "    for feature in df.columns:\n",
    "        if 'RUNNING' not in feature:\n",
    "            plot_feature(df, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data(df[FEATURES_NO_TIME])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_TREND_FEATURES = [\n",
    "    'M1 CURRENT', 'M1 TORQUE', 'PT4', 'D1 RPM', 'D1 CURRENT', 'D1 TORQUE',\n",
    "    'M2 RPM', 'M2 Amp', 'M2 Torque', 'CHARGE PT', 'CHARGE FLOW', 'M3 Amp',\n",
    "    'M3 Torque', 'Servo PT', 'SERVO FLOW', 'HSU IN', 'TT2', 'HSU OUT',\n",
    "    'M5 Amp', 'M5 Torque', 'M6 RPM', 'M6 Amp', 'M6 Torque', 'M7 RPM', 'M7 Amp',\n",
    "    'M7 Torque', 'Vibration 1', ' Vibration 2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGINEERED_FEATURES = [\n",
    "    'DRIVE POWER', 'LOAD POWER', 'CHARGE MECH POWER', 'CHARGE HYD POWER',\n",
    "    'SERVO MECH POWER', 'SERVO HYD POWER', 'SCAVENGE POWER',\n",
    "    'MAIN COOLER POWER', 'GEARBOX COOLER POWER'\n",
    "]\n",
    "df['DRIVE POWER'] = (df['M1 SPEED'] * df['M1 TORQUE'] * np.pi / 30 /\n",
    "                     1e3).astype(np.float32)\n",
    "df['LOAD POWER'] = abs(df['D1 RPM'] * df['D1 TORQUE'] * np.pi / 30 /\n",
    "                       1e3).astype(np.float32)\n",
    "df['CHARGE MECH POWER'] = (df['M2 RPM'] * df['M2 Torque'] * np.pi / 30 /\n",
    "                           1e3).astype(np.float32)\n",
    "df['CHARGE HYD POWER'] = (df['CHARGE PT'] * 1e5 * df['CHARGE FLOW'] * 1e-3 /\n",
    "                          60 / 1e3).astype(np.float32)\n",
    "df['SERVO MECH POWER'] = (df['M3 RPM'] * df['M3 Torque'] * np.pi / 30 /\n",
    "                          1e3).astype(np.float32)\n",
    "df['SERVO HYD POWER'] = (df['Servo PT'] * 1e5 * df['SERVO FLOW'] * 1e-3 / 60 /\n",
    "                         1e3).astype(np.float32)\n",
    "df['SCAVENGE POWER'] = (df['M5 RPM'] * df['M5 Torque'] * np.pi / 30 /\n",
    "                        1e3).astype(np.float32)\n",
    "df['MAIN COOLER POWER'] = (df['M6 RPM'] * df['M6 Torque'] * np.pi / 30 /\n",
    "                           1e3).astype(np.float32)\n",
    "df['GEARBOX COOLER POWER'] = (df['M7 RPM'] * df['M7 Torque'] * np.pi / 30 /\n",
    "                              1e3).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREND_FEATURES = ENGINEERED_FEATURES + [\n",
    "    'PT4', 'HSU IN', 'TT2', 'HSU OUT', 'Vibration 1', ' Vibration 2'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trends with `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_plot(df, period, plot=True):\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(nrows=len(TREND_FEATURES),\n",
    "                               ncols=4,\n",
    "                               sharex=True,\n",
    "                               figsize=(30, 60))\n",
    "\n",
    "    for i, column in enumerate(TREND_FEATURES):\n",
    "        res = seasonal_decompose(df[column],\n",
    "                                 period=int(period),\n",
    "                                 model='additive',\n",
    "                                 extrapolate_trend='freq')\n",
    "\n",
    "        df[f'{column} trend'] = res.trend\n",
    "        df[f'{column} seasonal'] = res.seasonal\n",
    "\n",
    "        if plot:\n",
    "            ax[i, 0].set_title(f'Decomposition of {column}', fontsize=16)\n",
    "            res.observed.plot(ax=ax[i, 0], legend=False)\n",
    "            ax[i, 0].set_ylabel('Observed', fontsize=14)\n",
    "            res.trend.plot(ax=ax[i, 1], legend=False)\n",
    "            ax[i, 1].set_ylabel('Trend', fontsize=14)\n",
    "            res.seasonal.plot(ax=ax[i, 2], legend=False)\n",
    "            ax[i, 2].set_ylabel('Seasonal', fontsize=14)\n",
    "            res.resid.plot(ax=ax[i, 3], legend=False)\n",
    "            ax[i, 3].set_ylabel('Residual', fontsize=14)\n",
    "    if plot:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose_plot(df, mean_test_dur_sec, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_TREND_FEATURES = TREND_FEATURES + [\n",
    "    f for f in df.columns if f.endswith('trend')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect mean and std of moving averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ma_mean_std(df, window):\n",
    "    for feature in df.columns:\n",
    "        if 'RUNNING' not in feature:\n",
    "            plt.figure(figsize=(20, 5), tight_layout=True)\n",
    "            plt.plot(df['RUNNING HOURS'],\n",
    "                     df[feature],\n",
    "                     label='observed',\n",
    "                     color='steelblue')\n",
    "            plt.plot(df['RUNNING HOURS'],\n",
    "                     df[feature].rolling(window=int(window)).mean(),\n",
    "                     label='mean moving average',\n",
    "                     color='indianred')\n",
    "            plt.plot(df['RUNNING HOURS'],\n",
    "                     df[feature].rolling(window=int(window)).std(),\n",
    "                     label='std moving average',\n",
    "                     color='seagreen')\n",
    "            plt.ylabel(feature)\n",
    "            plt.xlabel('RUNNING HOURS')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ma_mean_std(df[FINAL_TREND_FEATURES], mean_test_dur_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stationarity check with Augmented Dickey-Fuller unit root test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adfuller_results(df):\n",
    "    for feature in df.columns:\n",
    "        if 'RUNNING' not in feature:\n",
    "            result = adfuller(df[feature].values)\n",
    "            significance_level = 0.05\n",
    "            adf_stat = result[0]\n",
    "            p_val = result[1]\n",
    "            crit_val_1 = result[4]['1%']\n",
    "            crit_val_5 = result[4]['5%']\n",
    "            crit_val_10 = result[4]['10%']\n",
    "\n",
    "            if (p_val < significance_level) & (adf_stat < crit_val_1):\n",
    "                linecolor = 'forestgreen'\n",
    "            elif (p_val < significance_level) & (adf_stat < crit_val_5):\n",
    "                linecolor = 'orange'\n",
    "            elif (p_val < significance_level) & (adf_stat < crit_val_10):\n",
    "                linecolor = 'red'\n",
    "            else:\n",
    "                linecolor = 'purple'\n",
    "            plt.figure(figsize=(20, 5), tight_layout=True)\n",
    "            plt.plot(df['RUNNING HOURS'], df[feature], color=linecolor)\n",
    "            plt.title(\n",
    "                f'ADF Statistic {adf_stat:0.2f}, p-value: {p_val:0.2f}\\nCritical Values 1%: {crit_val_1:0.2f}, 5%: {crit_val_5:0.2f}, 10%: {crit_val_10:0.2f}',\n",
    "                fontsize=14)\n",
    "            plt.ylabel(feature, fontsize=14)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_adfuller_results(df[FINAL_TREND_FEATURES])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'Vibration 1'\n",
    "FEATURES = 'RUNNING HOURS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:int(0.8 * len(df))][[FEATURES, TARGET]]\n",
    "test = df.iloc[int(0.8 * len(df)):][[FEATURES, TARGET]]\n",
    "X = train.loc[:, FEATURES].values\n",
    "y = train.loc[:, TARGET].values\n",
    "X_test = test.loc[:, FEATURES].values\n",
    "y_test = test.loc[:, TARGET].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast_on_ma(df, feature, forecast, ma_window):\n",
    "    plt.figure(figsize=(20, 5), tight_layout=True)\n",
    "    plt.plot(df['RUNNING HOURS'], df[feature], label='observed')\n",
    "    plt.plot(df['RUNNING HOURS'],\n",
    "             df[feature].rolling(window=int(ma_window)).mean(),\n",
    "             label='moving average')\n",
    "    plt.plot(test['RUNNING HOURS'], forecast, label='forecast')\n",
    "    plt.xlabel('RUNNING HOURS')\n",
    "    plt.ylabel(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val(X_train, X_val, y_train, y_val, feature):\n",
    "    plt.figure(figsize=(20, 5), tight_layout=True)\n",
    "    plt.plot(X_train, y_train, color='steelblue', label='train')\n",
    "    plt.plot(X_val, y_val, color='darkorange', label='val')\n",
    "    plt.xlim(X[0], X[-1])\n",
    "    plt.xlabel('RUNNING HOURS')\n",
    "    plt.ylabel(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index('RUNNING TIME', inplace=True, drop=False)\n",
    "test.set_index('RUNNING TIME', inplace=True, drop=False)\n",
    "model = ExponentialSmoothing(train[TARGET],\n",
    "                             freq='S',\n",
    "                             trend='add',\n",
    "                             damped_trend=True).fit(smoothing_level=.5,\n",
    "                                                    optimized=True)\n",
    "forecast = model.forecast(len(test))\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast_on_ma(df, TARGET, forecast, mean_test_dur_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(forecast, test[TARGET], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(\n",
    "    df[TARGET].rolling(window=int(mean_test_dur_sec)).mean()[-len(forecast):],\n",
    "    test[TARGET],\n",
    "    squared=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (train_idx,\n",
    "          val_idx) in enumerate(TimeSeriesSplit(n_splits=5).split(X)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    if plot:\n",
    "        plot_train_val(X_train, X_val, y_train, y_val, TARGET)\n",
    "    model = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.10,\n",
    "        subsample=0.5,\n",
    "        colsample_bytree=1,\n",
    "        max_depth=5,\n",
    "    )\n",
    "    model.fit(X_train.reshape(-1, 1),\n",
    "              y_train.reshape(-1, 1),\n",
    "              eval_set=[(X_val.reshape(-1, 1), y_val.reshape(-1, 1))],\n",
    "              eval_metric='rmse',\n",
    "              verbose=True)\n",
    "dump(model, open(os.path.join(MODELS_PATH, 'xgb_vibr_1.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model.predict(X_test.reshape(-1, 1))\n",
    "plot_forecast_on_ma(df, TARGET, forecast, mean_test_dur_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting with `keras`"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38740d3277777e2cd7c6c2cc9d8addf5118fdf3f82b1b39231fd12aeac8aee8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
